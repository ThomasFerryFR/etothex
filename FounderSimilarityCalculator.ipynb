{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEOR 135: Applied Data Science for Venture Applications\n",
    "## The Holy Grail of Venture Capital\n",
    "\n",
    "Project Team: Julian Chan, Thomas Ferry, Mudit Goyal, Nitin Sampath, Yuan Zhou\n",
    "\n",
    "IPython Notebook: Julian Chan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "founders = pd.read_excel(\"data/Independent Variable Input.xlsx\")\n",
    "\n",
    "# Remove the founders for whom we only have their name and company name\n",
    "founders.dropna(axis=0, thresh=9, inplace=True)\n",
    "\n",
    "# Initialize weights for each feature; assume 2 columns are founder name and company name\n",
    "weights = np.array([np.random.uniform(0, 1) for _ in range(founders.shape[1] - 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FounderSimilarityCalculator:\n",
    "    def __init__(self, data, weights):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            data: pandas dataframe of feature values (assumes founder name is first column, company name is second column)\n",
    "            weights: array of weights for each feature to be used in determining \"distance\" between founders\n",
    "        \"\"\"\n",
    "        self.founders = data.iloc[:,0] # the first column is assumed to be founder name\n",
    "        self.companies = data.iloc[:,1] # the second column is assumed to be company name\n",
    "        self.features = data.iloc[:,2:]\n",
    "        self.weights = weights\n",
    "        self.sum_of_weights = np.sum(weights) # compute the sum of the weights as a normalizing factor for similarity\n",
    "        assert self.features.shape[1] == len(self.weights) # ensure that the # of weights corresponds to # of features\n",
    "    \n",
    "    def _weightedContributionToSimilarity(self, feature1, feature2, weight):\n",
    "        \"\"\"\n",
    "        Computes the weighted contribution of the current feature to the similarity measure.\n",
    "        \n",
    "        If the two values are the same, then we add 1*weight to the similarity score.\n",
    "        \n",
    "        For features whose values are continuous, the probability of 2 values being equal is very small, so we don't want\n",
    "        to penalize them for being different. We can use a smoother penalty based on how different they are. So, if the \n",
    "        two values are different,\n",
    "            1. Compute the absolute difference between the two values\n",
    "            2. Add 1/difference * weight to the similarity score\n",
    "        \n",
    "        Input:\n",
    "            feature1: feature of founder\n",
    "            feature2: corresponding feature of different founder\n",
    "            weight: weight on the feature\n",
    "        \"\"\"\n",
    "        if isinstance(feature1, str) and isinstance(feature2, str):\n",
    "            if feature1 == feature2:\n",
    "                return weight\n",
    "            else:\n",
    "                return 0\n",
    "        elif isinstance(feature1, float) and isinstance(feature2, float):\n",
    "            if not (np.isnan(feature1) or np.isnan(feature2)):\n",
    "                diff = np.abs(feature1 - feature2)\n",
    "                if diff <= 1:\n",
    "                    return weight\n",
    "                else:\n",
    "                    return 1/diff * weight\n",
    "            else:\n",
    "                return 0\n",
    "        return 0\n",
    "    \n",
    "    def _computeWeightedSimilarity(self, founder1_index, founder2_index):\n",
    "        \"\"\"\n",
    "        Computes the weighted similarity between 2 founders.\n",
    "        \n",
    "        Input:\n",
    "            founder1_index: integer index of founder 1\n",
    "            founder2_index: integer index of founder 2\n",
    "        \"\"\"\n",
    "        founder1 = self.founders.iloc[founder1_index]\n",
    "        founder2 = self.founders.iloc[founder2_index]\n",
    "        \n",
    "        features1 = self.features.iloc[founder1_index,:]\n",
    "        features2 = self.features.iloc[founder2_index,:]\n",
    "        \n",
    "        similarity = 0\n",
    "        for i in range(features1.shape[0]):\n",
    "            similarity += self._weightedContributionToSimilarity(features1[i], features2[i], self.weights[i])\n",
    "        \n",
    "        return similarity/self.sum_of_weights\n",
    "    \n",
    "    def findKClosestFounders(self, k, founder_index):\n",
    "        \"\"\"\n",
    "        Finds the k closest founders in terms of similarity to the founder corresponding to founder_index.\n",
    "        \n",
    "        Input:\n",
    "            k: # of most similar founders\n",
    "            founder_index: integer index of founder of whom we wish to find similar founders\n",
    "        \"\"\"\n",
    "        assert k < self.founders.shape[0]\n",
    "        \n",
    "        similarity = np.zeros(self.founders.shape[0])\n",
    "        \n",
    "        for i in range(self.founders.shape[0]):\n",
    "            if i == founder_index:\n",
    "                continue\n",
    "            similarity[i] = self._computeWeightedSimilarity(founder_index, i)\n",
    "            \n",
    "        min_indices = similarity.argsort()[::-1][:k]\n",
    "        \n",
    "        closest_founders = []\n",
    "        closest_companies = []\n",
    "        similarity_score = []\n",
    "        for i in min_indices:\n",
    "            closest_founders.append(self.founders.iloc[i])\n",
    "            closest_companies.append(self.companies.iloc[i])\n",
    "            similarity_score.append(similarity[i])\n",
    "        \n",
    "        return closest_founders, closest_companies, similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsc = FounderSimilarityCalculator(founders, weights)\n",
    "\n",
    "# Find the 5 closest founders\n",
    "desired_founder_index = 15\n",
    "closest_founders, closest_companies, similarity_score = fsc.findKClosestFounders(5, desired_founder_index)\n",
    "\n",
    "closest = list(zip(closest_founders, closest_companies, similarity_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data[\"name\"] = fsc.founders[desired_founder_index]\n",
    "data[\"company\"] = fsc.companies[desired_founder_index]\n",
    "data[\"size\"] = 200000\n",
    "data[\"Crunchbase\"] = \"www.crunchbase.com\"\n",
    "data[\"LinkedIn\"] = \"www.linkedin.com\"\n",
    "\n",
    "data[\"children\"] = []\n",
    "for tup in closest:\n",
    "    name = tup[0]\n",
    "    company = tup[1]\n",
    "    score = tup[2]\n",
    "    size = 150000\n",
    "    crunchbase = \"www.crunchbase.com\"\n",
    "    linkedin = \"www.linkedin.com\"\n",
    "    new_dict = {\"name\": name,\n",
    "               \"company\": company,\n",
    "               \"similar\": score,\n",
    "               \"size\": size,\n",
    "               \"Crunchbase\": crunchbase,\n",
    "               \"LinkedIn\": linkedin}\n",
    "    data[\"children\"].append(new_dict)\n",
    "\n",
    "with open('data.json', 'w') as outfile:  \n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load data.json\n",
    "{\"name\": \"Brendan Iribe\", \"company\": \"Oculus\", \"size\": 200000, \"Crunchbase\": \"www.crunchbase.com\", \"LinkedIn\": \"www.linkedin.com\", \"children\": [{\"name\": \"Emmett Shear\", \"company\": \"Twitch\", \"similar\": 0.32009511929814316, \"size\": 150000, \"Crunchbase\": \"www.crunchbase.com\", \"LinkedIn\": \"www.linkedin.com\"}, {\"name\": \"Tom Chavez\", \"company\": \"Krux\", \"similar\": 0.30880299431736213, \"size\": 150000, \"Crunchbase\": \"www.crunchbase.com\", \"LinkedIn\": \"www.linkedin.com\"}, {\"name\": \"Jan Koum\", \"company\": \"WhatsApp\", \"similar\": 0.3025643578774057, \"size\": 150000, \"Crunchbase\": \"www.crunchbase.com\", \"LinkedIn\": \"www.linkedin.com\"}, {\"name\": \"Anthony Casalena\", \"company\": \"Squarespace\", \"similar\": 0.3012168295107586, \"size\": 150000, \"Crunchbase\": \"www.crunchbase.com\", \"LinkedIn\": \"www.linkedin.com\"}, {\"name\": \"Tony Fadell\", \"company\": \"Nest Labs\", \"similar\": 0.29931359469750796, \"size\": 150000, \"Crunchbase\": \"www.crunchbase.com\", \"LinkedIn\": \"www.linkedin.com\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
